# Leo Numerical Optimization

## Build Guide

To compile this program, run:
```bash
leo build
```

To run this program, run:
```bash
leo run main
```
## Overview 

This example proves stocastic gradient descent as a simple Perceptron model over the Confidence dataset.

The logic was generated by [Otti](https://github.com/eniac/otti). The interesting optimization here, is that instead of proving the entire trace of stocastic gradient descent, we can merely prove that a set of weights is optimal (i.e. their loss is zero) given a set of datapoints.